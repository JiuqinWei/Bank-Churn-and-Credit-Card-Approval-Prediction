new_data$Gender <- ifelse(new_data$Gender == "M", 1, 0)
# Ensure the new 'Gender' column is of type integer
new_data$Gender <- as.integer(new_data$Gender)
# Check the data
str(new_data)
rm(new_data$Gender_dummy)
str(new_data)
new_data$Gender_dummy <- NULL
str(new_data)
# Create a frequency table of STATUS
print(table(new_data$STATUS))
print(table(new_data$mobile))
new_data$mobile = NULL
new_data$Car <- ifelse(new_data$Car == "Y", 1, 0)
new_data$Car <- as.integer(new_data$Car)
# Check the data
str(new_data)
new_data$Reality <- ifelse(new_data$Reality == "Y", 1, 0)
new_data$Reality <- as.integer(new_data$Reality)
# Check the data
str(new_data)
new_data$DAYS_BIRTH = NULL
new_data$DAYS_EMPLOYED = NULL
# Check the data
str(new_data)
print(table(new_data$wkphone))
print(table(new_data$phone))
print(table(new_data$email))
new_data$wkphone <- ifelse(new_data$wkphone == "Y", 1, 0)
new_data$wkphone <- as.integer(new_data$wkphone)
new_data$phone <- ifelse(new_data$phone == "Y", 1, 0)
new_data$phone <- as.integer(new_data$phone)
new_data$email <- ifelse(new_data$email == "Y", 1, 0)
new_data$email <- as.integer(new_data$email)
str(new_data)
# Read two data frames
data = read.csv("/Users/jiuqinwei/Documents/GitHub/STAT675-Final-Project/application_record.csv") # Applicants Demographic Data
record = read.csv("/Users/jiuqinwei/Documents/GitHub/STAT675-Final-Project/credit_record.csv") # Applicants Accounts Data
# Merging the data frames on 'ID'
new_data <- merge(data, record, by = "ID", all.x = TRUE)
# Feature Engineering
new_data$Age <- -new_data$DAYS_BIRTH / 365.25
new_data$Employment_Duration <- -new_data$DAYS_EMPLOYED / 365.25
new_data$DAYS_BIRTH = NULL
new_data$DAYS_EMPLOYED = NULL
# Check the data
str(new_data)
# Load necessary packages
library(dplyr)
library(tidyr)
library(MASS)
library(ggplot2)
library(xgboost)
library(corrplot)
library(cluster)
library(caret)
library(fastDummies)
library(glmnet)
# Read two data frames
data = read.csv("/Users/jiuqinwei/Documents/GitHub/STAT675-Final-Project/application_record.csv") # Applicants Demographic Data
record = read.csv("/Users/jiuqinwei/Documents/GitHub/STAT675-Final-Project/credit_record.csv") # Applicants Accounts Data
# Merging the data frames on 'ID'
new_data <- merge(data, record, by = "ID", all.x = TRUE)
# Renaming columns
new_data <- new_data %>%
rename(Gender = CODE_GENDER,
Car = FLAG_OWN_CAR,
Reality = FLAG_OWN_REALTY,
ChldNo = CNT_CHILDREN,
inc = AMT_INCOME_TOTAL,
edutp = NAME_EDUCATION_TYPE,
famtp = NAME_FAMILY_STATUS,
houtp = NAME_HOUSING_TYPE,
email = FLAG_EMAIL,
inctp = NAME_INCOME_TYPE,
mobile = FLAG_MOBIL,
wkphone = FLAG_WORK_PHONE,
phone = FLAG_PHONE,
famsize = CNT_FAM_MEMBERS,
occyp = OCCUPATION_TYPE)
# Feature Engineering
new_data$Age <- -new_data$DAYS_BIRTH / 365.25
new_data$Employment_Duration <- -new_data$DAYS_EMPLOYED / 365.25
new_data$DAYS_BIRTH = NULL
new_data$DAYS_EMPLOYED = NULL
# Identify duplicate values
# sum(duplicated(new_data)) # There is no duplicate value.
# Check for missing values in key columns
colSums(is.na(new_data[, c("Gender", "inc", "occyp", "STATUS")]))
# Filling missing 'occyp' based on the most frequent category per 'ID'
# new_data <- new_data %>%
#   group_by(ID) %>%
#  mutate(occyp = if_else(is.na(occyp), first(occyp[!is.na(occyp)]), occyp)) %>%
#  ungroup()
# Impute or remove missing values
new_data$occyp[new_data$occyp == ""] <- NA  # Convert empty strings to NA
new_data <- na.omit(new_data)  # Remove rows with any NA values
# Total missing values in the data frame
total_missing_values <- sum(is.na(new_data))
print(total_missing_values)
# Count missing values in each column
colSums(is.na(new_data))
# Create frequency table
print(table(new_data$STATUS))
print(table(new_data$mobile))
print(table(new_data$wkphone))
print(table(new_data$phone))
print(table(new_data$email))
new_data$mobile = NULL
# Plot the frequency of STATUS
barplot(table(new_data$STATUS),
main = "Frequency Plot of STATUS",
xlab = "STATUS",
ylab = "Frequency",
col = "skyblue")
# Check the data
str(new_data)
# Data Encoding
# Convert to binary features
new_data$Gender <- ifelse(new_data$Gender == "M", 1, 0)
new_data$Gender <- as.integer(new_data$Gender)
new_data$Car <- ifelse(new_data$Car == "Y", 1, 0)
new_data$Car <- as.integer(new_data$Car)
new_data$Reality <- ifelse(new_data$Reality == "Y", 1, 0)
new_data$Reality <- as.integer(new_data$Reality)
new_data$wkphone <- ifelse(new_data$wkphone == "Y", 1, 0)
new_data$wkphone <- as.integer(new_data$wkphone)
new_data$phone <- ifelse(new_data$phone == "Y", 1, 0)
new_data$phone <- as.integer(new_data$phone)
new_data$email <- ifelse(new_data$email == "Y", 1, 0)
new_data$email <- as.integer(new_data$email)
str(new_data)
print(table(new_data$wkphone))
print(table(new_data$phone))
print(table(new_data$email))
# Create frequency table
print(table(new_data$STATUS))
print(table(new_data$mobile))
# Load necessary packages
library(dplyr)
library(tidyr)
library(MASS)
library(ggplot2)
library(xgboost)
library(corrplot)
library(cluster)
library(caret)
library(fastDummies)
library(glmnet)
# Read two data frames
data = read.csv("/Users/jiuqinwei/Documents/GitHub/STAT675-Final-Project/application_record.csv") # Applicants Demographic Data
record = read.csv("/Users/jiuqinwei/Documents/GitHub/STAT675-Final-Project/credit_record.csv") # Applicants Accounts Data
# Merging the data frames on 'ID'
new_data <- merge(data, record, by = "ID", all.x = TRUE)
# Renaming columns
new_data <- new_data %>%
rename(Gender = CODE_GENDER,
Car = FLAG_OWN_CAR,
Reality = FLAG_OWN_REALTY,
ChldNo = CNT_CHILDREN,
inc = AMT_INCOME_TOTAL,
edutp = NAME_EDUCATION_TYPE,
famtp = NAME_FAMILY_STATUS,
houtp = NAME_HOUSING_TYPE,
email = FLAG_EMAIL,
inctp = NAME_INCOME_TYPE,
mobile = FLAG_MOBIL,
wkphone = FLAG_WORK_PHONE,
phone = FLAG_PHONE,
famsize = CNT_FAM_MEMBERS,
occyp = OCCUPATION_TYPE)
# Feature Engineering
new_data$Age <- -new_data$DAYS_BIRTH / 365.25
new_data$Employment_Duration <- -new_data$DAYS_EMPLOYED / 365.25
new_data$DAYS_BIRTH = NULL
new_data$DAYS_EMPLOYED = NULL
# Identify duplicate values
# sum(duplicated(new_data)) # There is no duplicate value.
# Check for missing values in key columns
colSums(is.na(new_data[, c("Gender", "inc", "occyp", "STATUS")]))
# Filling missing 'occyp' based on the most frequent category per 'ID'
# new_data <- new_data %>%
#   group_by(ID) %>%
#  mutate(occyp = if_else(is.na(occyp), first(occyp[!is.na(occyp)]), occyp)) %>%
#  ungroup()
# Impute or remove missing values
new_data$occyp[new_data$occyp == ""] <- NA  # Convert empty strings to NA
new_data <- na.omit(new_data)  # Remove rows with any NA values
# Total missing values in the data frame
total_missing_values <- sum(is.na(new_data))
print(total_missing_values)
# Count missing values in each column
colSums(is.na(new_data))
# Create frequency table
print(table(new_data$STATUS))
print(table(new_data$mobile))
print(table(new_data$wkphone))
print(table(new_data$phone))
print(table(new_data$email))
new_data$mobile = NULL
str(new_data)
str(new_data)
gc()
# Check the data
str(new_data)
# Load necessary packages
library(dplyr)
library(tidyr)
library(MASS)
library(ggplot2)
library(xgboost)
library(corrplot)
library(cluster)
library(caret)
library(fastDummies)
library(glmnet)
# Read two data frames
data = read.csv("/Users/jiuqinwei/Documents/GitHub/STAT675-Final-Project/application_record.csv") # Applicants Demographic Data
install.packages("ggplot2")
install.packages("dplyr")
install.packages("corrplot")
library(ggplot2)
library(dplyr)
library(corrplot)
data = read.csv("/Users/jiuqinwei/Documents/GitHub/STAT675-Final-Project/Bank Customer Churn Prediction.csv")
str(data)
# Check for missing values
sum(is.na(data))
# Remove duplicate rows, if any
data <- data %>% distinct()
# Histograms for numerical variables
hist(data$age, main = "Age Distribution", xlab = "Age", col = "skyblue")
hist(data$credit_score, main = "Credit Score Distribution", xlab = "Credit Score", col = "lightgreen")
hist(data$balance, main = "Balance Distribution", xlab = "Balance", col = "salmon")
# Bar plots for categorical variables
ggplot(data, aes(x = gender)) + geom_bar(fill = "turquoise") + labs(title = "Gender Distribution")
ggplot(data, aes(x = as.factor(products_number))) + geom_bar(fill = "gold") + labs(title = "Products Number Distribution")
View(data)
library(caret)
install.packages("caret")
hist(data$credit_score, main = "Credit Score Distribution", xlab = "Credit Score", col = "lightgreen")
# Histograms for numerical variables
hist(data$age, main = "Age Distribution", xlab = "Age", col = "skyblue")
hist(data$balance, main = "Balance Distribution", xlab = "Balance", col = "salmon")
# Boxplots showing the distribution of balance and age by churn
ggplot(data, aes(x = as.factor(churn), y = age, fill = as.factor(churn))) +
geom_boxplot() + labs(title = "Age Distribution by Churn", x = "Churn", y = "Age")
ggplot(data, aes(x = as.factor(churn), y = balance, fill = as.factor(churn))) +
geom_boxplot() + labs(title = "Balance Distribution by Churn", x = "Churn", y = "Balance")
# Load required packages
library(ggplot2)
library(dplyr)
library(corrplot)
library(caret)
# Boxplots showing the distribution of balance and age by churn
ggplot(data, aes(x = as.factor(churn), y = age, fill = as.factor(churn))) +
geom_boxplot() + labs(title = "Age Distribution by Churn", x = "Churn", y = "Age")
ggplot(data, aes(x = as.factor(churn), y = balance, fill = as.factor(churn))) +
geom_boxplot() + labs(title = "Balance Distribution by Churn", x = "Churn", y = "Balance")
library(ggplot2)
library(dplyr)
library(corrplot)
library(caret)
# Create a training set and a test set
set.seed(42)
training_rows <- createDataPartition(data$churn, p = 0.8, list = FALSE)
train_data <- data[training_rows, ]
test_data <- data[-training_rows, ]
# Logistic Regression Model
model <- glm(churn ~ ., data = train_data, family = binomial)
# Summary of the model
summary(model)
library(glmnet)
### Logistic Regression with Lasso Penalty using glmnet
# Prepare matrix for glmnet
x_matrix <- model.matrix(churn ~ . - 1, data = train_data)
y_vector <- train_data$churn
# Fit the model with Lasso penalty
lasso_model <- cv.glmnet(x_matrix, y_vector, family = "binomial", alpha = 1)
# Plot the coefficients
plot(lasso_model)
### GAM
# Fit a GAM model
gam_model <- gam(churn ~ s(age) + s(credit_score) + gender + country, family = binomial, data = train_data)
library(mgcv)
### GAM
# Fit a GAM model
gam_model <- gam(churn ~ s(age) + s(credit_score) + gender + country, family = binomial, data = train_data)
# Summary of GAM model
summary(gam_model)
# Plot the coefficients
plot(lasso_model)
model_2 <- glm(churn ~ credit_score + country + gender + age + balance
+ products_number + active_member, data = train_data, family = binomial)
summary(model_2)
### Logistic Regression with Lasso Penalty using glmnet
# Prepare matrix for glmnet
x_matrix <- model.matrix(churn ~ credit_score + country + gender + age + balance
+ products_number + active_member - 1, data = train_data)
y_vector <- train_data$churn
# Fit the model with Lasso penalty
lasso_model <- cv.glmnet(x_matrix, y_vector, family = "binomial", alpha = 1)
# Plot the coefficients
plot(lasso_model)
### GAM
# Fit a GAM model
gam_model <- gam(churn ~ s(age) + s(credit_score) + gender + country, family = binomial, data = train_data)
# Summary of GAM model
summary(gam_model)
# Load necessary packages
library(dplyr)
library(tidyr)
library(MASS)
library(ggplot2)
library(xgboost)
library(corrplot)
library(cluster)
library(caret)
library(fastDummies)
library(glmnet)
library(nnet)
library(pheatmap)
library(brant)
library(randomForest)
library(ranger)
# Read two data frames
data = read.csv("/Users/jiuqinwei/Documents/GitHub/STAT675-Final-Project/application_record.csv") # Applicants Demographic Data
record = read.csv("/Users/jiuqinwei/Documents/GitHub/STAT675-Final-Project/credit_record.csv") # Applicants Accounts Data
# Merging the data frames on 'ID'
new_data <- merge(data, record, by = "ID", all.x = TRUE)
# Renaming columns
new_data <- new_data %>%
rename(Gender = CODE_GENDER,
Car = FLAG_OWN_CAR,
Realty = FLAG_OWN_REALTY,
ChldNo = CNT_CHILDREN,
inc = AMT_INCOME_TOTAL,
edutp = NAME_EDUCATION_TYPE,
famtp = NAME_FAMILY_STATUS,
houtp = NAME_HOUSING_TYPE,
email = FLAG_EMAIL,
inctp = NAME_INCOME_TYPE,
mobile = FLAG_MOBIL,
wkphone = FLAG_WORK_PHONE,
phone = FLAG_PHONE,
famsize = CNT_FAM_MEMBERS,
occyp = OCCUPATION_TYPE)
# Feature Engineering
new_data$Age <- -new_data$DAYS_BIRTH / 365.25
new_data$Employment_Duration <- -new_data$DAYS_EMPLOYED / 365.25
new_data$DAYS_BIRTH = NULL
new_data$DAYS_EMPLOYED = NULL
new_data$mobile = NULL # All the values are "1".
# Identify duplicate values
# sum(duplicated(new_data)) # There is no duplicate value.
# Check for missing values in key columns
colSums(is.na(new_data[, c("Gender", "inc", "occyp", "STATUS")]))
# Filling missing 'occyp' based on the most frequent category per 'ID'
# new_data <- new_data %>%
#    group_by(ID) %>%
#    mutate(occyp = if_else(is.na(occyp), first(occyp[!is.na(occyp)]), occyp)) %>%
#    ungroup()
# Impute or remove missing values
new_data$occyp[new_data$occyp == ""] <- NA  # Convert empty strings to NA
new_data <- na.omit(new_data)  # Remove rows with any NA values
# Total missing values in the data frame
total_missing_values <- sum(is.na(new_data))
print(total_missing_values)
# Count missing values in each column
colSums(is.na(new_data))
# Create frequency table
print(table(new_data$STATUS))
# Plot the frequency of STATUS
barplot(table(new_data$STATUS),
main = "Frequency Plot of STATUS",
xlab = "STATUS",
ylab = "Frequency",
col = "skyblue")
View(data)
data = read.csv("/Users/jiuqinwei/Documents/GitHub/STAT675-Final-Project/application_record.csv") # Applicants Demographic Data
record = read.csv("/Users/jiuqinwei/Documents/GitHub/STAT675-Final-Project/credit_record.csv") # Applicants Accounts Data
data$OCCUPATION_TYPE = NULL
# Merging the data frames on 'ID'
new_data <- merge(data, record, by = "ID", all.x = TRUE)
# Renaming columns
new_data <- new_data %>%
rename(Gender = CODE_GENDER,
Car = FLAG_OWN_CAR,
Realty = FLAG_OWN_REALTY,
ChldNo = CNT_CHILDREN,
inc = AMT_INCOME_TOTAL,
edutp = NAME_EDUCATION_TYPE,
famtp = NAME_FAMILY_STATUS,
houtp = NAME_HOUSING_TYPE,
email = FLAG_EMAIL,
inctp = NAME_INCOME_TYPE,
mobile = FLAG_MOBIL,
wkphone = FLAG_WORK_PHONE,
phone = FLAG_PHONE,
famsize = CNT_FAM_MEMBERS)
# Feature Engineering
new_data$Age <- -new_data$DAYS_BIRTH / 365.25
new_data$Employment_Duration <- -new_data$DAYS_EMPLOYED / 365.25
new_data$DAYS_BIRTH = NULL
new_data$DAYS_EMPLOYED = NULL
new_data$mobile = NULL # All the values are "1".
View(new_data)
# Total missing values in the data frame
total_missing_values <- sum(is.na(new_data))
print(total_missing_values)
# Count missing values in each column
colSums(is.na(new_data))
# Read two data frames
data = read.csv("/Users/jiuqinwei/Documents/GitHub/STAT675-Final-Project/application_record.csv") # Applicants Demographic Data
record = read.csv("/Users/jiuqinwei/Documents/GitHub/STAT675-Final-Project/credit_record.csv") # Applicants Accounts Data
# Merging the data frames on 'ID'
new_data <- merge(data, record, by = "ID", all.x = TRUE)
# Renaming columns
new_data <- new_data %>%
rename(Gender = CODE_GENDER,
Car = FLAG_OWN_CAR,
Realty = FLAG_OWN_REALTY,
ChldNo = CNT_CHILDREN,
inc = AMT_INCOME_TOTAL,
edutp = NAME_EDUCATION_TYPE,
famtp = NAME_FAMILY_STATUS,
houtp = NAME_HOUSING_TYPE,
email = FLAG_EMAIL,
inctp = NAME_INCOME_TYPE,
mobile = FLAG_MOBIL,
wkphone = FLAG_WORK_PHONE,
phone = FLAG_PHONE,
famsize = CNT_FAM_MEMBERS,
occyp = OCCUPATION_TYPE)
# Feature Engineering
new_data$Age <- -new_data$DAYS_BIRTH / 365.25
new_data$Employment_Duration <- -new_data$DAYS_EMPLOYED / 365.25
new_data$DAYS_BIRTH = NULL
new_data$DAYS_EMPLOYED = NULL
new_data$mobile = NULL # All the values are "1".
# Check for missing values in key columns
colSums(is.na(new_data[, c("Gender", "inc", "occyp", "STATUS")]))
# Impute or remove missing values
new_data$occyp[new_data$occyp == ""] <- NA  # Convert empty strings to NA
new_data <- na.omit(new_data)  # Remove rows with any NA values
# Total missing values in the data frame
total_missing_values <- sum(is.na(new_data))
print(total_missing_values)
# Create frequency table
print(table(new_data$STATUS))
# Load necessary packages
library(dplyr)
library(tidyr)
library(MASS)
library(ggplot2)
library(xgboost)
library(corrplot)
library(cluster)
library(caret)
library(fastDummies)
library(glmnet)
library(nnet)
library(pheatmap)
library(brant)
library(randomForest)
library(ranger)
# Read two data frames
data = read.csv("/Users/jiuqinwei/Documents/GitHub/STAT675-Final-Project/application_record.csv") # Applicants Demographic Data
record = read.csv("/Users/jiuqinwei/Documents/GitHub/STAT675-Final-Project/credit_record.csv") # Applicants Accounts Data
# Merging the data frames on 'ID'
new_data <- merge(data, record, by = "ID", all.x = TRUE)
# Renaming columns
new_data <- new_data %>%
rename(Gender = CODE_GENDER,
Car = FLAG_OWN_CAR,
Realty = FLAG_OWN_REALTY,
ChldNo = CNT_CHILDREN,
inc = AMT_INCOME_TOTAL,
edutp = NAME_EDUCATION_TYPE,
famtp = NAME_FAMILY_STATUS,
houtp = NAME_HOUSING_TYPE,
email = FLAG_EMAIL,
inctp = NAME_INCOME_TYPE,
mobile = FLAG_MOBIL,
wkphone = FLAG_WORK_PHONE,
phone = FLAG_PHONE,
famsize = CNT_FAM_MEMBERS,
occyp = OCCUPATION_TYPE)
# Feature Engineering
new_data$Age <- -new_data$DAYS_BIRTH / 365.25
new_data$Employment_Duration <- -new_data$DAYS_EMPLOYED / 365.25
new_data$DAYS_BIRTH = NULL
new_data$DAYS_EMPLOYED = NULL
new_data$mobile = NULL # All the values are "1".
# Identify duplicate values
# sum(duplicated(new_data)) # There is no duplicate value.
# Check for missing values in key columns
colSums(is.na(new_data[, c("Gender", "inc", "occyp", "STATUS")]))
# Filling missing 'occyp' based on the most frequent category per 'ID'
# new_data <- new_data %>%
#    group_by(ID) %>%
#    mutate(occyp = if_else(is.na(occyp), first(occyp[!is.na(occyp)]), occyp)) %>%
#    ungroup()
# Impute or remove missing values
new_data$occyp[new_data$occyp == ""] <- NA  # Convert empty strings to NA
new_data <- na.omit(new_data)  # Remove rows with any NA values
# Total missing values in the data frame
total_missing_values <- sum(is.na(new_data))
print(total_missing_values)
# Count missing values in each column
colSums(is.na(new_data))
str(new_data)
